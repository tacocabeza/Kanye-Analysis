{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/tacocabeza/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/tacocabeza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tacocabeza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/tacocabeza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import *\n",
    "import flatten_json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "#To plot the graphs\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "#library used to count the frequency of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#To create the sentiment analysis model, tokenization and lemmatization\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import word_tokenize\n",
    "import nltk.data\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"ye\" by Kanye West...\n",
      "Wrote ye.json.\n",
      "Searching for \"Jesus is King\" by Kanye West...\n",
      "Wrote Jesus is King.json.\n",
      "Searching for \"The Life of Pablo\" by Kanye West...\n",
      "Wrote The Life of Pablo.json.\n",
      "Searching for \"Yeezus\" by Kanye West...\n",
      "Wrote Yeezus.json.\n",
      "Searching for \"My Beautiful Dark Twisted Fantasy\" by Kanye West...\n",
      "Wrote My Beautiful Dark Twisted Fantasy.json.\n",
      "Searching for \"808s Heartbreak\" by Kanye West...\n",
      "Wrote 808s Heartbreak.json.\n",
      "Searching for \"Graduation\" by Kanye West...\n",
      "Wrote Graduation.json.\n",
      "Searching for \"Late Registration\" by Kanye West...\n"
     ]
    }
   ],
   "source": [
    "token = \"leRPf88bBR2Nk3f96p-IUwzG9zG5sJ2Q93VNLr3r2fVXCvE4nvCEvJXjaoZqKxfn\"\n",
    "\n",
    "df0 = search_library(\"ye\",\"Kanye West\",token)\n",
    "df1 = search_library(\"Jesus is King\", \"Kanye West\", token)\n",
    "df2 = search_library(\"The Life of Pablo\", \"Kanye West\", token)\n",
    "df3 = search_library(\"Yeezus\", \"Kanye West\", token)\n",
    "df4 = search_library(\"My Beautiful Dark Twisted Fantasy\", \"Kanye West\", token)\n",
    "df5 = search_library(\"808s Heartbreak\", \"Kanye West\", token)\n",
    "df6 = search_library(\"Graduation\", \"Kanye West\", token)\n",
    "df7 = search_library(\"Late Registration\", \"Kanye West\", token)\n",
    "df8 = search_library(\"The College Dropout\", \"Kanyewest\", token)\n",
    "\n",
    "df0.append(df1)\n",
    "df0.append(df2)\n",
    "df0.append(df3)\n",
    "df0.append(df4)\n",
    "df0.append(df5)\n",
    "df0.append(df6)\n",
    "df0.append(df7)\n",
    "df0.append(df8)\n",
    "\n",
    "df = clean_lyrics(df0,\"lyrics\")\n",
    "\n",
    "\n",
    "df.to_csv('lyrics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unique(list1): \n",
    "     # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x) \n",
    "    \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#list used to store the words\n",
    "words = []\n",
    "#iterate trought each lyric and split unique words appending the result into the words list\n",
    "df = df.reset_index(drop=True)\n",
    "for word in df['lyrics'].tolist():\n",
    "    words.append(unique(lyrics_to_words(word).split()))\n",
    "\n",
    "#create the new column with the information of words lists \n",
    "df['words'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe of all the  words used in lyrics and its decades \n",
    "\n",
    "#list used to store the information\n",
    "set_words = []\n",
    "set_song = []\n",
    "\n",
    "#Iterate trought each word and decade and stores them into the new lists\n",
    "for i in df.index:\n",
    "    for word in df['words'].iloc[i]:\n",
    "        set_words.append(word)\n",
    "        set_song.append(df['album'].iloc[i])\n",
    "\n",
    "#create the new data frame  with the information of words and decade lists \n",
    "words_df = pd.DataFrame({'words':set_words,'song':set_song})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['070']\n",
    "# count the frequency of each word that don't have on the stop_words lists          \n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "#Create a dataframe called data_cv to store the the number of times the word was used in  a lyric based their decades\n",
    "text_cv = cv.fit_transform(words_df['words'].iloc[:])\n",
    "data_cv = pd.DataFrame(text_cv.toarray(),columns=cv.get_feature_names())\n",
    "data_cv['song'] = words_df['song']\n",
    "\n",
    "#created a dataframe that Sums the ocurrence frequency of each word and group the result by decade\n",
    "vect_words = data_cv.groupby('song').sum().T\n",
    "vect_words = vect_words.reset_index(level=0).rename(columns ={'index':'words'})\n",
    "vect_words = vect_words.rename_axis(columns='')\n",
    "\n",
    "#Save the data into a csv file\n",
    "vect_words.to_csv('words.csv',index=False)\n",
    "\n",
    "vect_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud(df,row,col):\n",
    "    wc = WordCloud( background_color=\"white\",colormap=\"Dark2\",max_font_size=100,random_state=15)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    for index, value in enumerate(df.columns[1:]):\n",
    "\n",
    "        top_dict = dict(zip(df['words'].tolist(),df[value].tolist()))\n",
    "        wc.generate_from_frequencies(top_dict)\n",
    "        plt.subplot(row,col,index+1)\n",
    "        plt.imshow(wc,interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"{value}\",fontsize=15) \n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def words_stats(df,main_df):\n",
    "    unique_words = []\n",
    "    total_words = []\n",
    "    total_news = []\n",
    "    years = []\n",
    "    for value in df.columns[1:]:\n",
    "         unique_words.append(np.count_nonzero(df[value]))\n",
    "         total_words.append(sum(df[value]))\n",
    "         years.append(str(value))\n",
    "         total_news.append(main_df['decade'][main_df['decade']==value].count())\n",
    "    \n",
    "    data = pd.DataFrame({'decade':years,'unique words':unique_words,'total words':total_words,'total songs':total_news})\n",
    "    data['words per songs'] = round(data['total words'] / data['total songs'],0)\n",
    "    data['words per songs'] = data['words per songs'].astype('int')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(vect_words, 2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
